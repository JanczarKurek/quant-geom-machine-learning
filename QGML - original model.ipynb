{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original model\n",
    "\n",
    "This notebook contains an implementation of the original model from Swaddle (2017) adapted to use the full complex form of unitaries. It has been adapted in order that both the GRU global decomposition network and fully-connected local decomposition network form a sequence of networks that are called sequentially.\n",
    "\n",
    "Code has also been added to calculate the fidelity of estimated unitary sequences against ground-truth unitary sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import qutip as qt\n",
    "from matplotlib import pyplot as plt\n",
    "import random as rn\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preamble\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,optimizers,constraints,initializers,Model,backend\n",
    "import pickle\n",
    "import time\n",
    "import zipfile    \n",
    "import os\n",
    "\n",
    "\n",
    "import qutip as qt\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import random as rn\n",
    "import os\n",
    "import itertools as itr\n",
    "from itertools import combinations\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from functools import reduce\n",
    "import csv\n",
    "\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM, LSTMCell, GRU\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from numpy import array\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, Image\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "import pickle\n",
    "from flattenunitary import flattenunitary\n",
    "from flattenunitary import realise\n",
    "from dataprocess import dataprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customlayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load dataset'''\n",
    "import pickle\n",
    "su2dim = 2\n",
    "nseg = 10\n",
    "ntrain = 1000\n",
    "hscale = 0.1 #\\delta tj (i.e. h in code or duration of pulse)\n",
    "su2ngen = None #0: \\Lambda_0 in \\Delta; 1: \\Lambda_0 \\in su2n\n",
    "holo = None #whether training data to be generated from Boozer\n",
    "\n",
    "with open('su{0}_ntrain{1}_nseg{2}_hscale{3}_su2gen{4}.pickle'\n",
    "          .format(su2dim,ntrain, nseg, hscale, su2ngen), 'rb') as handle:\n",
    "    gentest = pickle.load(handle)\n",
    "\n",
    "'''Convert dictionary to tuple so behaves like an object once loaded'''\n",
    "from collections import namedtuple\n",
    "gentest = namedtuple('Struct', gentest.keys())(*gentest.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''=========Real and imaginary parts of (Uj)======'''\n",
    "\n",
    "Ujseq_real = (tf.math.real(np.asarray(gentest.Uj_master_array)))\n",
    "Ujseq_imag = (tf.math.imag(np.asarray(gentest.Uj_master_array)))\n",
    "Ujseq = tf.convert_to_tensor(np.asarray(gentest.Uj_master_array))\n",
    "Ujinputseq = np.asarray(gentest.Uj_master_realised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Recreate xtrain function from QMLcontrol model: constructs U_T by accumulating (U_j).'''\n",
    "from itertools import accumulate\n",
    "Ujarray = np.asarray(gentest.Uj_master_realised)\n",
    "def xtrainmethod(Ujarray):\n",
    "    evolve = lambda U_j,U: U @ U_j\n",
    "    acclist = []\n",
    "    for list1 in Ujarray:\n",
    "        acclist.append(list(accumulate(list1, evolve))[-1])\n",
    "    xtrain = tf.convert_to_tensor(np.asarray(acclist))\n",
    "    return xtrain\n",
    "xtrain = xtrainmethod(Ujarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origdim\n",
      "(4, 4)\n",
      "reshape shape\n",
      "160\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4446 - Reshapereal_loss: 0.4393 - Reshapeimag_loss: 0.0054 - val_loss: 0.3511 - val_Reshapereal_loss: 0.3502 - val_Reshapeimag_loss: 9.0110e-04\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2774 - Reshapereal_loss: 0.2771 - Reshapeimag_loss: 3.3751e-04 - val_loss: 0.2090 - val_Reshapereal_loss: 0.2089 - val_Reshapeimag_loss: 8.4841e-05\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1598 - Reshapereal_loss: 0.1598 - Reshapeimag_loss: 4.2224e-05 - val_loss: 0.1180 - val_Reshapereal_loss: 0.1180 - val_Reshapeimag_loss: 2.3001e-05\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0917 - Reshapereal_loss: 0.0917 - Reshapeimag_loss: 1.9774e-05 - val_loss: 0.0701 - val_Reshapereal_loss: 0.0701 - val_Reshapeimag_loss: 1.8134e-05\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0566 - Reshapereal_loss: 0.0566 - Reshapeimag_loss: 1.7314e-05 - val_loss: 0.0453 - val_Reshapereal_loss: 0.0453 - val_Reshapeimag_loss: 1.6541e-05\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0379 - Reshapereal_loss: 0.0379 - Reshapeimag_loss: 1.5954e-05 - val_loss: 0.0317 - val_Reshapereal_loss: 0.0316 - val_Reshapeimag_loss: 1.5357e-05\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0273 - Reshapereal_loss: 0.0272 - Reshapeimag_loss: 1.4871e-05 - val_loss: 0.0234 - val_Reshapereal_loss: 0.0234 - val_Reshapeimag_loss: 1.4664e-05\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0206 - Reshapereal_loss: 0.0206 - Reshapeimag_loss: 1.4073e-05 - val_loss: 0.0181 - val_Reshapereal_loss: 0.0181 - val_Reshapeimag_loss: 1.3487e-05\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0162 - Reshapereal_loss: 0.0161 - Reshapeimag_loss: 1.3066e-05 - val_loss: 0.0144 - val_Reshapereal_loss: 0.0144 - val_Reshapeimag_loss: 1.2511e-05\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0130 - Reshapereal_loss: 0.0130 - Reshapeimag_loss: 1.2167e-05 - val_loss: 0.0118 - val_Reshapereal_loss: 0.0118 - val_Reshapeimag_loss: 1.1830e-05\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0108 - Reshapereal_loss: 0.0108 - Reshapeimag_loss: 1.1491e-05 - val_loss: 0.0098 - val_Reshapereal_loss: 0.0098 - val_Reshapeimag_loss: 1.0900e-05\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0091 - Reshapereal_loss: 0.0091 - Reshapeimag_loss: 1.0715e-05 - val_loss: 0.0083 - val_Reshapereal_loss: 0.0083 - val_Reshapeimag_loss: 1.0268e-05\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0077 - Reshapereal_loss: 0.0077 - Reshapeimag_loss: 1.0080e-05 - val_loss: 0.0072 - val_Reshapereal_loss: 0.0072 - val_Reshapeimag_loss: 9.8379e-06\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0067 - Reshapereal_loss: 0.0067 - Reshapeimag_loss: 9.4029e-06 - val_loss: 0.0062 - val_Reshapereal_loss: 0.0062 - val_Reshapeimag_loss: 9.0561e-06\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0058 - Reshapereal_loss: 0.0058 - Reshapeimag_loss: 8.9013e-06 - val_loss: 0.0055 - val_Reshapereal_loss: 0.0055 - val_Reshapeimag_loss: 8.4757e-06\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0052 - Reshapereal_loss: 0.0052 - Reshapeimag_loss: 8.5593e-0 - 0s 2ms/step - loss: 0.0051 - Reshapereal_loss: 0.0051 - Reshapeimag_loss: 8.3775e-06 - val_loss: 0.0048 - val_Reshapereal_loss: 0.0048 - val_Reshapeimag_loss: 7.8604e-06\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0046 - Reshapereal_loss: 0.0045 - Reshapeimag_loss: 7.8064e-06 - val_loss: 0.0043 - val_Reshapereal_loss: 0.0043 - val_Reshapeimag_loss: 7.4024e-06\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0041 - Reshapereal_loss: 0.0041 - Reshapeimag_loss: 7.3050e-06 - val_loss: 0.0039 - val_Reshapereal_loss: 0.0038 - val_Reshapeimag_loss: 6.8680e-06\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0037 - Reshapereal_loss: 0.0036 - Reshapeimag_loss: 6.7861e-06 - val_loss: 0.0035 - val_Reshapereal_loss: 0.0035 - val_Reshapeimag_loss: 6.3191e-06\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0033 - Reshapereal_loss: 0.0033 - Reshapeimag_loss: 6.4146e-06 - val_loss: 0.0031 - val_Reshapereal_loss: 0.0031 - val_Reshapeimag_loss: 5.9897e-06\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0030 - Reshapereal_loss: 0.0030 - Reshapeimag_loss: 5.9598e-06 - val_loss: 0.0029 - val_Reshapereal_loss: 0.0029 - val_Reshapeimag_loss: 5.5128e-06\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0027 - Reshapereal_loss: 0.0027 - Reshapeimag_loss: 5.5706e-06 - val_loss: 0.0026 - val_Reshapereal_loss: 0.0026 - val_Reshapeimag_loss: 5.4250e-06\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0025 - Reshapereal_loss: 0.0025 - Reshapeimag_loss: 5.2930e-06 - val_loss: 0.0024 - val_Reshapereal_loss: 0.0024 - val_Reshapeimag_loss: 4.9857e-06\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0023 - Reshapereal_loss: 0.0023 - Reshapeimag_loss: 4.8118e-06 - val_loss: 0.0022 - val_Reshapereal_loss: 0.0022 - val_Reshapeimag_loss: 4.5862e-06\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0021 - Reshapereal_loss: 0.0021 - Reshapeimag_loss: 4.5319e-06 - val_loss: 0.0020 - val_Reshapereal_loss: 0.0020 - val_Reshapeimag_loss: 4.3174e-06\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0019 - Reshapereal_loss: 0.0019 - Reshapeimag_loss: 4.2609e-06 - val_loss: 0.0019 - val_Reshapereal_loss: 0.0019 - val_Reshapeimag_loss: 4.0152e-06\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0018 - Reshapereal_loss: 0.0018 - Reshapeimag_loss: 3.9393e-06 - val_loss: 0.0017 - val_Reshapereal_loss: 0.0017 - val_Reshapeimag_loss: 3.5837e-06\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0017 - Reshapereal_loss: 0.0017 - Reshapeimag_loss: 3.6815e-06 - val_loss: 0.0016 - val_Reshapereal_loss: 0.0016 - val_Reshapeimag_loss: 3.5207e-06\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0015 - Reshapereal_loss: 0.0015 - Reshapeimag_loss: 3.4330e-06 - val_loss: 0.0015 - val_Reshapereal_loss: 0.0015 - val_Reshapeimag_loss: 3.1149e-06\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0014 - Reshapereal_loss: 0.0014 - Reshapeimag_loss: 3.2100e-06 - val_loss: 0.0014 - val_Reshapereal_loss: 0.0014 - val_Reshapeimag_loss: 2.9102e-06\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0013 - Reshapereal_loss: 0.0013 - Reshapeimag_loss: 3.0234e-06 - val_loss: 0.0013 - val_Reshapereal_loss: 0.0013 - val_Reshapeimag_loss: 2.7355e-06\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0012 - Reshapereal_loss: 0.0012 - Reshapeimag_loss: 2.7254e-06 - val_loss: 0.0012 - val_Reshapereal_loss: 0.0012 - val_Reshapeimag_loss: 2.4643e-06\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0012 - Reshapereal_loss: 0.0012 - Reshapeimag_loss: 2.6160e-06 - val_loss: 0.0011 - val_Reshapereal_loss: 0.0011 - val_Reshapeimag_loss: 2.3301e-06\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0011 - Reshapereal_loss: 0.0011 - Reshapeimag_loss: 2.4515e-06 - val_loss: 0.0011 - val_Reshapereal_loss: 0.0011 - val_Reshapeimag_loss: 2.2176e-06\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0010 - Reshapereal_loss: 0.0010 - Reshapeimag_loss: 2.2017e-06 - val_loss: 9.9421e-04 - val_Reshapereal_loss: 9.9203e-04 - val_Reshapeimag_loss: 2.1712e-06\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.6250e-04 - Reshapereal_loss: 9.6046e-04 - Reshapeimag_loss: 2.0381e-06 - val_loss: 9.3428e-04 - val_Reshapereal_loss: 9.3242e-04 - val_Reshapeimag_loss: 1.8595e-06\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 9.0451e-04 - Reshapereal_loss: 9.0264e-04 - Reshapeimag_loss: 1.8753e-06 - val_loss: 8.7878e-04 - val_Reshapereal_loss: 8.7706e-04 - val_Reshapeimag_loss: 1.7184e-06\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.5125e-04 - Reshapereal_loss: 8.4950e-04 - Reshapeimag_loss: 1.7445e-06 - val_loss: 8.2767e-04 - val_Reshapereal_loss: 8.2595e-04 - val_Reshapeimag_loss: 1.7138e-06\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.0179e-04 - Reshapereal_loss: 8.0015e-04 - Reshapeimag_loss: 1.6357e-06 - val_loss: 7.8005e-04 - val_Reshapereal_loss: 7.7853e-04 - val_Reshapeimag_loss: 1.5188e-06\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.5603e-04 - Reshapereal_loss: 7.5450e-04 - Reshapeimag_loss: 1.5280e-06 - val_loss: 7.3555e-04 - val_Reshapereal_loss: 7.3417e-04 - val_Reshapeimag_loss: 1.3879e-06\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.1345e-04 - Reshapereal_loss: 7.1205e-04 - Reshapeimag_loss: 1.3965e-06 - val_loss: 6.9433e-04 - val_Reshapereal_loss: 6.9295e-04 - val_Reshapeimag_loss: 1.3848e-06\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.7388e-04 - Reshapereal_loss: 6.7252e-04 - Reshapeimag_loss: 1.3555e-06 - val_loss: 6.5632e-04 - val_Reshapereal_loss: 6.5514e-04 - val_Reshapeimag_loss: 1.1773e-06\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.3701e-04 - Reshapereal_loss: 6.3575e-04 - Reshapeimag_loss: 1.2570e-06 - val_loss: 6.2039e-04 - val_Reshapereal_loss: 6.1927e-04 - val_Reshapeimag_loss: 1.1227e-06\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.0249e-04 - Reshapereal_loss: 6.0134e-04 - Reshapeimag_loss: 1.1535e-06 - val_loss: 5.8719e-04 - val_Reshapereal_loss: 5.8614e-04 - val_Reshapeimag_loss: 1.0503e-06\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.7031e-04 - Reshapereal_loss: 5.6928e-04 - Reshapeimag_loss: 1.0359e-06 - val_loss: 5.5624e-04 - val_Reshapereal_loss: 5.5529e-04 - val_Reshapeimag_loss: 9.4338e-07\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.4020e-04 - Reshapereal_loss: 5.3923e-04 - Reshapeimag_loss: 9.7079e-07 - val_loss: 5.2691e-04 - val_Reshapereal_loss: 5.2602e-04 - val_Reshapeimag_loss: 8.8324e-07\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.1211e-04 - Reshapereal_loss: 5.1118e-04 - Reshapeimag_loss: 9.2492e-07 - val_loss: 4.9937e-04 - val_Reshapereal_loss: 4.9856e-04 - val_Reshapeimag_loss: 8.1354e-07\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.8558e-04 - Reshapereal_loss: 4.8475e-04 - Reshapeimag_loss: 8.3759e-07 - val_loss: 4.7385e-04 - val_Reshapereal_loss: 4.7308e-04 - val_Reshapeimag_loss: 7.7362e-07\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.6084e-04 - Reshapereal_loss: 4.6003e-04 - Reshapeimag_loss: 8.1114e-07 - val_loss: 4.4981e-04 - val_Reshapereal_loss: 4.4907e-04 - val_Reshapeimag_loss: 7.3329e-07\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.3751e-04 - Reshapereal_loss: 4.3677e-04 - Reshapeimag_loss: 7.4419e-07 - val_loss: 4.2731e-04 - val_Reshapereal_loss: 4.2661e-04 - val_Reshapeimag_loss: 7.0044e-07\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.1560e-04 - Reshapereal_loss: 4.1491e-04 - Reshapeimag_loss: 6.8693e-07 - val_loss: 4.0601e-04 - val_Reshapereal_loss: 4.0540e-04 - val_Reshapeimag_loss: 6.1721e-07\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.9496e-04 - Reshapereal_loss: 3.9430e-04 - Reshapeimag_loss: 6.5771e-07 - val_loss: 3.8600e-04 - val_Reshapereal_loss: 3.8540e-04 - val_Reshapeimag_loss: 5.9524e-07\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.7549e-04 - Reshapereal_loss: 3.7490e-04 - Reshapeimag_loss: 5.9132e-07 - val_loss: 3.6693e-04 - val_Reshapereal_loss: 3.6639e-04 - val_Reshapeimag_loss: 5.3673e-07\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.5718e-04 - Reshapereal_loss: 3.5662e-04 - Reshapeimag_loss: 5.5767e-07 - val_loss: 3.4918e-04 - val_Reshapereal_loss: 3.4864e-04 - val_Reshapeimag_loss: 5.3985e-07\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.3987e-04 - Reshapereal_loss: 3.3935e-04 - Reshapeimag_loss: 5.1539e-07 - val_loss: 3.3215e-04 - val_Reshapereal_loss: 3.3169e-04 - val_Reshapeimag_loss: 4.5817e-07\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.2350e-04 - Reshapereal_loss: 3.2302e-04 - Reshapeimag_loss: 4.7876e-07 - val_loss: 3.1630e-04 - val_Reshapereal_loss: 3.1583e-04 - val_Reshapeimag_loss: 4.6995e-07\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.0807e-04 - Reshapereal_loss: 3.0761e-04 - Reshapeimag_loss: 4.6921e-07 - val_loss: 3.0122e-04 - val_Reshapereal_loss: 3.0076e-04 - val_Reshapeimag_loss: 4.5517e-07\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.9345e-04 - Reshapereal_loss: 2.9303e-04 - Reshapeimag_loss: 4.2330e-07 - val_loss: 2.8694e-04 - val_Reshapereal_loss: 2.8656e-04 - val_Reshapeimag_loss: 3.8156e-07\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.7962e-04 - Reshapereal_loss: 2.7922e-04 - Reshapeimag_loss: 3.9977e-07 - val_loss: 2.7356e-04 - val_Reshapereal_loss: 2.7322e-04 - val_Reshapeimag_loss: 3.4659e-07\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.6658e-04 - Reshapereal_loss: 2.6618e-04 - Reshapeimag_loss: 3.9585e-07 - val_loss: 2.6074e-04 - val_Reshapereal_loss: 2.6039e-04 - val_Reshapeimag_loss: 3.4810e-07\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.5418e-04 - Reshapereal_loss: 2.5380e-04 - Reshapeimag_loss: 3.7787e-07 - val_loss: 2.4863e-04 - val_Reshapereal_loss: 2.4830e-04 - val_Reshapeimag_loss: 3.3183e-07\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.4234e-04 - Reshapereal_loss: 2.4201e-04 - Reshapeimag_loss: 3.2950e-07 - val_loss: 2.3730e-04 - val_Reshapereal_loss: 2.3700e-04 - val_Reshapeimag_loss: 3.0791e-07\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.3120e-04 - Reshapereal_loss: 2.3089e-04 - Reshapeimag_loss: 3.1458e-07 - val_loss: 2.2625e-04 - val_Reshapereal_loss: 2.2596e-04 - val_Reshapeimag_loss: 2.8540e-07\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.2058e-04 - Reshapereal_loss: 2.2028e-04 - Reshapeimag_loss: 2.9253e-07 - val_loss: 2.1595e-04 - val_Reshapereal_loss: 2.1569e-04 - val_Reshapeimag_loss: 2.5921e-07\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.1052e-04 - Reshapereal_loss: 2.1025e-04 - Reshapeimag_loss: 2.7476e-07 - val_loss: 2.0612e-04 - val_Reshapereal_loss: 2.0588e-04 - val_Reshapeimag_loss: 2.3878e-07\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.0100e-04 - Reshapereal_loss: 2.0073e-04 - Reshapeimag_loss: 2.6908e-07 - val_loss: 1.9679e-04 - val_Reshapereal_loss: 1.9656e-04 - val_Reshapeimag_loss: 2.3642e-07\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.9190e-04 - Reshapereal_loss: 1.9165e-04 - Reshapeimag_loss: 2.4694e-07 - val_loss: 1.8804e-04 - val_Reshapereal_loss: 1.8779e-04 - val_Reshapeimag_loss: 2.5221e-07\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8327e-04 - Reshapereal_loss: 1.8304e-04 - Reshapeimag_loss: 2.3139e-07 - val_loss: 1.7948e-04 - val_Reshapereal_loss: 1.7926e-04 - val_Reshapeimag_loss: 2.2539e-07\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7505e-04 - Reshapereal_loss: 1.7483e-04 - Reshapeimag_loss: 2.2234e-07 - val_loss: 1.7145e-04 - val_Reshapereal_loss: 1.7126e-04 - val_Reshapeimag_loss: 1.9729e-07\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6722e-04 - Reshapereal_loss: 1.6701e-04 - Reshapeimag_loss: 2.0441e-07 - val_loss: 1.6390e-04 - val_Reshapereal_loss: 1.6372e-04 - val_Reshapeimag_loss: 1.8946e-07\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5980e-04 - Reshapereal_loss: 1.5960e-04 - Reshapeimag_loss: 1.9971e-07 - val_loss: 1.5652e-04 - val_Reshapereal_loss: 1.5633e-04 - val_Reshapeimag_loss: 1.8670e-07\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5269e-04 - Reshapereal_loss: 1.5249e-04 - Reshapeimag_loss: 1.9237e-07 - val_loss: 1.4963e-04 - val_Reshapereal_loss: 1.4947e-04 - val_Reshapeimag_loss: 1.5971e-07\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4594e-04 - Reshapereal_loss: 1.4577e-04 - Reshapeimag_loss: 1.7031e-07 - val_loss: 1.4298e-04 - val_Reshapereal_loss: 1.4281e-04 - val_Reshapeimag_loss: 1.6935e-07\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3950e-04 - Reshapereal_loss: 1.3933e-04 - Reshapeimag_loss: 1.7150e-07 - val_loss: 1.3672e-04 - val_Reshapereal_loss: 1.3653e-04 - val_Reshapeimag_loss: 1.8663e-07\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3338e-04 - Reshapereal_loss: 1.3321e-04 - Reshapeimag_loss: 1.7467e-07 - val_loss: 1.3068e-04 - val_Reshapereal_loss: 1.3053e-04 - val_Reshapeimag_loss: 1.4931e-07\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2753e-04 - Reshapereal_loss: 1.2737e-04 - Reshapeimag_loss: 1.5827e-07 - val_loss: 1.2497e-04 - val_Reshapereal_loss: 1.2483e-04 - val_Reshapeimag_loss: 1.4447e-07\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2193e-04 - Reshapereal_loss: 1.2179e-04 - Reshapeimag_loss: 1.4747e-07 - val_loss: 1.1953e-04 - val_Reshapereal_loss: 1.1939e-04 - val_Reshapeimag_loss: 1.3633e-07\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1661e-04 - Reshapereal_loss: 1.1647e-04 - Reshapeimag_loss: 1.3428e-07 - val_loss: 1.1432e-04 - val_Reshapereal_loss: 1.1418e-04 - val_Reshapeimag_loss: 1.4211e-07\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1152e-04 - Reshapereal_loss: 1.1139e-04 - Reshapeimag_loss: 1.2715e-07 - val_loss: 1.0931e-04 - val_Reshapereal_loss: 1.0919e-04 - val_Reshapeimag_loss: 1.1883e-07\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0667e-04 - Reshapereal_loss: 1.0655e-04 - Reshapeimag_loss: 1.1832e-07 - val_loss: 1.0454e-04 - val_Reshapereal_loss: 1.0443e-04 - val_Reshapeimag_loss: 1.1003e-07\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0203e-04 - Reshapereal_loss: 1.0192e-04 - Reshapeimag_loss: 1.0805e-07 - val_loss: 1.0012e-04 - val_Reshapereal_loss: 1.0001e-04 - val_Reshapeimag_loss: 1.0799e-07\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.7612e-05 - Reshapereal_loss: 9.7501e-05 - Reshapeimag_loss: 1.1049e-07 - val_loss: 9.5762e-05 - val_Reshapereal_loss: 9.5619e-05 - val_Reshapeimag_loss: 1.4264e-07\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.3417e-05 - Reshapereal_loss: 9.3297e-05 - Reshapeimag_loss: 1.1987e-07 - val_loss: 9.1612e-05 - val_Reshapereal_loss: 9.1501e-05 - val_Reshapeimag_loss: 1.1103e-07\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.9343e-05 - Reshapereal_loss: 8.9243e-05 - Reshapeimag_loss: 9.9394e-08 - val_loss: 8.7633e-05 - val_Reshapereal_loss: 8.7547e-05 - val_Reshapeimag_loss: 8.6009e-08\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.5474e-05 - Reshapereal_loss: 8.5391e-05 - Reshapeimag_loss: 8.3362e-08 - val_loss: 8.3804e-05 - val_Reshapereal_loss: 8.3729e-05 - val_Reshapeimag_loss: 7.4974e-08\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.1785e-05 - Reshapereal_loss: 8.1702e-05 - Reshapeimag_loss: 8.3147e-08 - val_loss: 8.0202e-05 - val_Reshapereal_loss: 8.0128e-05 - val_Reshapeimag_loss: 7.3428e-08\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.8262e-05 - Reshapereal_loss: 7.8181e-05 - Reshapeimag_loss: 8.0630e-08 - val_loss: 7.6772e-05 - val_Reshapereal_loss: 7.6694e-05 - val_Reshapeimag_loss: 7.7480e-08\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.4904e-05 - Reshapereal_loss: 7.4822e-05 - Reshapeimag_loss: 8.2058e-08 - val_loss: 7.3429e-05 - val_Reshapereal_loss: 7.3360e-05 - val_Reshapeimag_loss: 6.8734e-08\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.1663e-05 - Reshapereal_loss: 7.1591e-05 - Reshapeimag_loss: 7.1928e-08 - val_loss: 7.0294e-05 - val_Reshapereal_loss: 7.0222e-05 - val_Reshapeimag_loss: 7.1726e-08\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.8585e-05 - Reshapereal_loss: 6.8509e-05 - Reshapeimag_loss: 7.6160e-08 - val_loss: 6.7315e-05 - val_Reshapereal_loss: 6.7245e-05 - val_Reshapeimag_loss: 6.9410e-08\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.5639e-05 - Reshapereal_loss: 6.5578e-05 - Reshapeimag_loss: 6.1428e-08 - val_loss: 6.4412e-05 - val_Reshapereal_loss: 6.4355e-05 - val_Reshapeimag_loss: 5.7112e-08\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.2810e-05 - Reshapereal_loss: 6.2750e-05 - Reshapeimag_loss: 6.0315e-08 - val_loss: 6.1623e-05 - val_Reshapereal_loss: 6.1565e-05 - val_Reshapeimag_loss: 5.7592e-08\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.0117e-05 - Reshapereal_loss: 6.0061e-05 - Reshapeimag_loss: 5.5800e-08 - val_loss: 5.8970e-05 - val_Reshapereal_loss: 5.8917e-05 - val_Reshapeimag_loss: 5.3153e-08\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.7522e-05 - Reshapereal_loss: 5.7470e-05 - Reshapeimag_loss: 5.2127e-08 - val_loss: 5.6408e-05 - val_Reshapereal_loss: 5.6364e-05 - val_Reshapeimag_loss: 4.4829e-08\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.5047e-05 - Reshapereal_loss: 5.4995e-05 - Reshapeimag_loss: 5.2090e-08 - val_loss: 5.4041e-05 - val_Reshapereal_loss: 5.3982e-05 - val_Reshapeimag_loss: 5.9534e-08\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.2681e-05 - Reshapereal_loss: 5.2630e-05 - Reshapeimag_loss: 5.1341e-08 - val_loss: 5.1674e-05 - val_Reshapereal_loss: 5.1628e-05 - val_Reshapeimag_loss: 4.6271e-08\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.0411e-05 - Reshapereal_loss: 5.0360e-05 - Reshapeimag_loss: 5.0143e-08 - val_loss: 4.9461e-05 - val_Reshapereal_loss: 4.9423e-05 - val_Reshapeimag_loss: 3.8344e-08\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.8237e-05 - Reshapereal_loss: 4.8194e-05 - Reshapeimag_loss: 4.3290e-08 - val_loss: 4.7320e-05 - val_Reshapereal_loss: 4.7283e-05 - val_Reshapeimag_loss: 3.7164e-08\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.6171e-05 - Reshapereal_loss: 4.6117e-05 - Reshapeimag_loss: 5.4121e-08 - val_loss: 4.5352e-05 - val_Reshapereal_loss: 4.5247e-05 - val_Reshapeimag_loss: 1.0514e-07\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.4179e-05 - Reshapereal_loss: 4.4133e-05 - Reshapeimag_loss: 4.5747e-08 - val_loss: 4.3370e-05 - val_Reshapereal_loss: 4.3327e-05 - val_Reshapeimag_loss: 4.2702e-08\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.2601\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.0614\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0145\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0098\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0084\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0072\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0067\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0066\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0067\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.0101\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.0068\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0054\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0065\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0266 - val_loss: 0.0078\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0071\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0065\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0054\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.0116\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0080\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.025 - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0074\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0073\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0084\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.0071\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0074\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.0058\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0062\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0065\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.0071\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0056\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0057\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0082\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0051\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0054\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0084\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0055\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0057\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0119\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0056\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0058\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0056\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0055\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0064\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0067\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0060\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0102\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0055\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0067\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0061\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0053\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0073\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0071\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0063\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0070\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0058\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0080\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0061\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0053\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0058\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0072\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0054\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0056\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0065\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0056\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0057\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0067\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0052\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0099\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0058\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0056\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.018 - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0061\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0066\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0056\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0061\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0056\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0064\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0068\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0053\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0060\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0067\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0063\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0060\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0055\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0073\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0101\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0060\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0064\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0069\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0053\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0076\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0057\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0064\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0068\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0062\n",
      "tf.Tensor(\n",
      "[[0.87568626 0.87569706 0.87570128 ... 0.87570081 0.87569038 0.87568804]\n",
      " [0.8999335  0.89992944 0.89993429 ... 0.89992271 0.89992781 0.89992745]\n",
      " [0.90600676 0.90601789 0.9060088  ... 0.90600816 0.90599868 0.9059896 ]\n",
      " ...\n",
      " [0.45682533 0.45682277 0.45682584 ... 0.45681916 0.45682299 0.45681405]\n",
      " [0.68229256 0.68229079 0.68228894 ... 0.68226387 0.68228186 0.68226077]\n",
      " [0.97361053 0.97360766 0.97361506 ... 0.97360941 0.97360916 0.97361114]], shape=(1000, 10), dtype=float64)\n",
      "0.7233127647479247\n"
     ]
    }
   ],
   "source": [
    "'''==============GRU: | Global decomposition model | Input: UT | Output: (Uj) =================='''\n",
    "'''GRU: combining basic GRU model from Swaddle'''\n",
    "'''Inputs: the target unitary (U_T), output is global decomposition (U_j)'''\n",
    "\n",
    "Ujinputseq = np.asarray(gentest.Uj_master_realised)\n",
    "Ujinputseq.shape\n",
    "Ujcoefinput = tf.convert_to_tensor(np.asarray(gentest.Uj_master_coef_list), dtype=tf.float64)\n",
    "\n",
    "_su2n_realdim = gentest.su2n_dim * 2\n",
    "seg = gentest.segments\n",
    "ntrain = gentest.ntraining\n",
    "deltadim = np.asarray(gentest.su_2n_delta).shape[0]\n",
    "\n",
    "coefdim = seg * deltadim\n",
    "'''In QMLmodel class coefdim is: self.coef_numb_seg'''\n",
    "Ujcoeflabel = np.asarray(gentest.Uj_master_coef_list)\n",
    "tot = deltadim * gentest.segments\n",
    "\n",
    "origdim = (xtrain.shape[1], xtrain.shape[2])\n",
    "tf.print('origdim')\n",
    "tf.print(origdim)\n",
    "fidones_seg = tf.ones((gentest.ntraining,gentest.segments))\n",
    "tf.print('reshape shape')\n",
    "tf.print(seg * _su2n_realdim * _su2n_realdim)\n",
    "original_inputs = tf.keras.Input(shape=origdim, name='UTnput', batch_size=None)\n",
    "y1 = layers.Reshape((-1,_su2n_realdim *_su2n_realdim,))(original_inputs)\n",
    "\n",
    "totalflat = gentest.segments*gentest.su2n_dim*gentest.su2n_dim\n",
    "GRUreal = layers.GRU(totalflat, return_sequences=True, activation='tanh', name='GRUreal')(y1)\n",
    "GRUimag = layers.GRU(totalflat, return_sequences=True, activation='tanh', name='GRUimag')(y1)\n",
    "Reshapereal = layers.Reshape((gentest.segments,gentest.su2n_dim,gentest.su2n_dim,),name='Reshapereal')(GRUreal)\n",
    "Reshapeimag = layers.Reshape((gentest.segments,gentest.su2n_dim,gentest.su2n_dim,), name='Reshapeimag')(GRUimag)\n",
    "\n",
    "'''GRU model'''\n",
    "'''MSE flattened input Ujseq for loss'''\n",
    "grumod2 = Model(inputs=original_inputs, outputs=[Reshapereal,Reshapeimag], name='seqmod')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "MSE = tf.keras.losses.MeanSquaredError()\n",
    "grumod2.compile(optimizer, loss=[MSE,MSE])\n",
    "   \n",
    "'''=======Train global GRU model============='''\n",
    "epochs=100\n",
    "csv_logger = CSVLogger('origgru1.csv')\n",
    "h = grumod2.fit(xtrain,[Ujseq_real,Ujseq_imag],epochs=epochs, verbose=1, \n",
    "                validation_data=(xtrain,[Ujseq_real,Ujseq_imag]),\n",
    "                batch_size=10, validation_split = 0.25, shuffle=True,callbacks=[csv_logger])\n",
    "\n",
    "\n",
    "'''=======Prediction: use model to predict unitaries (global decomposition)=========='''\n",
    "grutens = grumod2.predict([xtrain, Ujseq_real,Ujseq_imag])\n",
    "tfconvert = tf.convert_to_tensor(grutens)\n",
    "freal = tfconvert[0]\n",
    "fimag = tfconvert[1]\n",
    "\n",
    "\n",
    "'''==============FC model: | Local decomposition model | Input: (U_j) | Output: (c_j) =================='''\n",
    "'''Description: trained on coefficients. Reuses above layers.'''\n",
    "inputUre = layers.Input(shape=(gentest.segments,gentest.su2n_dim,gentest.su2n_dim,), name='input2', batch_size=None)\n",
    "inputUim = layers.Input(shape=(gentest.segments,gentest.su2n_dim,gentest.su2n_dim,), name='input3', batch_size=None)\n",
    "concat = layers.Concatenate(axis=-1,name='concatlayer')([inputUre,inputUim])\n",
    "flatten = layers.Flatten()(concat)\n",
    "tot = deltadim * gentest.segments\n",
    "d1 = layers.Dense(tot, activation='tanh', name='Dense1')(flatten)\n",
    "d1 = layers.Dropout(0.2)(d1)\n",
    "d1 = layers.Dense(tot, activation='tanh', name='Dense2')(d1)\n",
    "d1 = layers.Dropout(0.2)(d1)\n",
    "d1 = layers.Dense(tot, activation='tanh', name='Dense3')(d1)\n",
    "d1 = layers.Dropout(0.2)(d1)\n",
    "d1 = layers.Dense(tot, activation='tanh', name='Dense4')(d1)\n",
    "coefmod = Model(inputs=[inputUre,inputUim], outputs=d1, name='coefmod')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "coefmod.compile(optimizer, loss=MSE)\n",
    "#epochs=2\n",
    "csv_logger = CSVLogger('orig_su8d_FC.csv')\n",
    "Ujcoefinput = tf.convert_to_tensor(np.asarray(gentest.Uj_master_coef_list), dtype=tf.float64)\n",
    "shape = (-1,Ujcoefinput.shape[1] * Ujcoefinput.shape[2])\n",
    "Ujcoeflabel = tf.reshape(Ujcoefinput,shape)\n",
    "'''=======train: train model (local decomposition)=========='''\n",
    "h1 = coefmod.fit([Ujseq_real,Ujseq_imag],Ujcoeflabel,epochs=epochs, verbose=1, \n",
    "                 batch_size=10, validation_split = 0.25, shuffle=True,callbacks=[csv_logger])\n",
    "\n",
    "\n",
    "'''=======Prediction: use model to predict coefficients (controls)=========='''\n",
    "coefpred = coefmod.predict([freal,fimag])\n",
    "\n",
    "\n",
    "\n",
    "'''===========Model: Reconstruct unitaries from estimated unitaries using\n",
    "generators, then compare fidelity with original sequence (Uj)'''\n",
    "seg = gentest.segments\n",
    "from customlayers import ham_est_simple,unitary_simple\n",
    "ham_est_layer_simple = ham_est_simple(gentest.su_2n_delta,seg, name='ham_layer')\n",
    "su2nidentity = tf.convert_to_tensor(np.identity(gentest.su2n_dim), dtype=np.complex128)\n",
    "unitary_simp = unitary_simple(seg, su2nidentity, gentest.su2n_dim, name='unitaryreconstruct')\n",
    "coefinput = layers.Input(shape=(coefpred.shape[1],), name='coefinput', batch_size=None)\n",
    "h1 = ham_est_layer_simple(coefinput)\n",
    "u1 = unitary_simp(h1)\n",
    "unitarymod = Model(inputs=coefinput, outputs=u1, name='coefmod')  \n",
    "#unitarymod.summary()\n",
    "unitarymodpred = unitarymod.predict(coefpred)\n",
    "'''Note: unitarymod is not trained.'''\n",
    "\n",
    "'''Now check using fidelity model above'''\n",
    "\n",
    "unconvert = tf.convert_to_tensor(unitarymodpred)\n",
    "unconvert.shape\n",
    "unreal = tf.math.real(unconvert)\n",
    "unimag = tf.math.imag(unconvert)\n",
    "\n",
    "'''=======Second model, check fidelity of this output=========='''\n",
    "tfconvert = tf.convert_to_tensor(grutens)\n",
    "shp = tfconvert.shape\n",
    "origshape = (shp[2],shp[3],shp[4])\n",
    "fidreal = layers.Input(shape=origshape, name='fidinput1', batch_size=None)\n",
    "fidimag = layers.Input(shape=origshape, name='fidinput2', batch_size=None)\n",
    "y = recombcomplex(name='unitaryoutput')([fidreal,fidimag])\n",
    "\n",
    "inputUre = layers.Input(shape=(gentest.segments,gentest.su2n_dim,gentest.su2n_dim,), name='input2', batch_size=None)\n",
    "inputUim = layers.Input(shape=(gentest.segments,gentest.su2n_dim,gentest.su2n_dim,), name='input3', batch_size=None)\n",
    "y_fid = fidmulti_unitary(gentest.su2n_dim, name='finalfidelity')([inputUre,inputUim,y])\n",
    " \n",
    "fidmod = Model(inputs=[fidreal,fidimag,inputUre,inputUim], outputs=y_fid, name='fidmod')\n",
    "\n",
    "'''=========Calculate fidelities for estimated (\\hat{U}j) that are constructed using the\n",
    "coefficients above and generators with the ground-trut (U_j). Store as a tensor of fidelities.'''\n",
    "uncheck = fidmod([unreal,unimag,Ujseq_real,Ujseq_imag])\n",
    "print(uncheck)\n",
    "'''Find average operator fidelity across examples'''\n",
    "avf = tf.reduce_mean(uncheck).numpy()\n",
    "print(avf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
